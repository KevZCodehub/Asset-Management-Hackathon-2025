{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Forecast Example (Small Subset)\n",
    "\n",
    "This notebook demonstrates building a simple next-month stock price forecast using an ARIMA model on a small subset of the large dataset (`data/ret_sample.csv`). We:\n",
    "\n",
    "- Load a few tickers and dates to keep memory small\n",
    "- Aggregate to monthly prices for one company\n",
    "- Fit an ARIMA model\n",
    "- Forecast next month and visualize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bn/cx_ppcpx0ngbpf4h354g9_k80000gn/T/ipykernel_91901/4039349432.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.max_rows\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     19\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.width\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m project_root \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mparents[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     22\u001b[0m data_path \u001b[38;5;241m=\u001b[39m project_root \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mret_sample.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing data at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure statsmodels is available\n",
    "try:\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "except Exception:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"statsmodels==0.14.2\"], stdout=subprocess.DEVNULL)\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "project_root = Path(__file__).resolve().parents[2]\n",
    "data_path = project_root / \"ret_sample.csv\"\n",
    "print(f\"Using data at: {data_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunked loader: detect schema and sample a few tickers\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "def detect_columns(cols: List[str]) -> Tuple[Optional[str], Optional[str], Optional[str], Optional[str]]:\n",
    "    lower = {c.lower(): c for c in cols}\n",
    "    # Likely names\n",
    "    date_candidates = [\"date\", \"datadate\", \"pricedate\", \"time\", \"datetime\"]\n",
    "    id_candidates = [\"asset_id\", \"ticker\", \"permno\", \"gvkey\", \"id\", \"asset\", \"symbol\"]\n",
    "    price_candidates = [\"price\", \"prc\", \"adj_close\", \"adjclose\", \"close\", \"px_last\"]\n",
    "    ret_candidates = [\"ret\", \"return\", \"stock_ret\", \"retx\", \"simple_return\"]\n",
    "\n",
    "    def pick(cands):\n",
    "        for c in cands:\n",
    "            if c in lower:\n",
    "                return lower[c]\n",
    "        return None\n",
    "\n",
    "    return pick(date_candidates), pick(id_candidates), pick(price_candidates), pick(ret_candidates)\n",
    "\n",
    "\n",
    "def read_small_subset(csv_path: Path, max_ids: int = 3, max_rows: int = 200_000) -> pd.DataFrame:\n",
    "    # Peek to detect schema and sample ids\n",
    "    head_df = pd.read_csv(csv_path, nrows=2000)\n",
    "    date_col, id_col, price_col, ret_col = detect_columns(list(head_df.columns))\n",
    "    if id_col is None or date_col is None:\n",
    "        raise ValueError(\"Could not detect required date/id columns. Please rename or provide a smaller sample.\")\n",
    "\n",
    "    # Choose up to max_ids from the head sample\n",
    "    candidate_ids = head_df[id_col].dropna().astype(str).unique().tolist()[:max_ids]\n",
    "    print(f\"Detected columns -> date: {date_col}, id: {id_col}, price: {price_col}, ret: {ret_col}\")\n",
    "    print(f\"Selected {len(candidate_ids)} ids: {candidate_ids}\")\n",
    "\n",
    "    usecols = [date_col, id_col]\n",
    "    if price_col: usecols.append(price_col)\n",
    "    if ret_col: usecols.append(ret_col)\n",
    "\n",
    "    chunks = []\n",
    "    total = 0\n",
    "    for chunk in pd.read_csv(csv_path, usecols=usecols, chunksize=200_000):\n",
    "        mask = chunk[id_col].astype(str).isin(candidate_ids)\n",
    "        filtered = chunk.loc[mask]\n",
    "        chunks.append(filtered)\n",
    "        total += len(filtered)\n",
    "        if total >= max_rows:\n",
    "            break\n",
    "\n",
    "    df = pd.concat(chunks, ignore_index=True)\n",
    "    # Parse dates and sort\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "    df = df.dropna(subset=[date_col, id_col]).sort_values([id_col, date_col]).reset_index(drop=True)\n",
    "    return df, date_col, id_col, price_col, ret_col\n",
    "\n",
    "subset_df, DATE_COL, ID_COL, PRICE_COL, RET_COL = read_small_subset(data_path)\n",
    "subset_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare one company monthly series\n",
    "\n",
    "# Choose the first id with enough observations\n",
    "counts = subset_df.groupby(ID_COL)[DATE_COL].count().sort_values(ascending=False)\n",
    "chosen_id = counts.index[0]\n",
    "print(f\"Chosen id: {chosen_id} (n={counts.iloc[0]})\")\n",
    "\n",
    "company_df = subset_df[subset_df[ID_COL].astype(str) == str(chosen_id)].copy()\n",
    "\n",
    "# Prefer price; if missing, reconstruct from returns assuming base 100\n",
    "if PRICE_COL and PRICE_COL in company_df.columns:\n",
    "    company_df = company_df[[DATE_COL, PRICE_COL]].dropna()\n",
    "    company_df = company_df.rename(columns={PRICE_COL: \"price\"})\n",
    "else:\n",
    "    if RET_COL is None or RET_COL not in company_df.columns:\n",
    "        raise ValueError(\"Neither price nor returns found for the selected id.\")\n",
    "    tmp = company_df[[DATE_COL, RET_COL]].dropna().rename(columns={RET_COL: \"ret\"})\n",
    "    tmp = tmp.sort_values(DATE_COL)\n",
    "    tmp[\"price\"] = 100 * (1 + tmp[\"ret\"]).cumprod()\n",
    "    company_df = tmp[[DATE_COL, \"price\"]]\n",
    "\n",
    "company_df = company_df.sort_values(DATE_COL)\n",
    "company_df = company_df.set_index(DATE_COL)\n",
    "\n",
    "# Aggregate to month-end price\n",
    "monthly = company_df.resample(\"M\").last().dropna()\n",
    "print(monthly.head())\n",
    "print(monthly.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARIMA(1,1,1) and forecast next month\n",
    "\n",
    "# Check we have enough data\n",
    "if len(monthly) < 24:\n",
    "    print(f\"Warning: only {len(monthly)} monthly points; ARIMA may be unstable.\")\n",
    "\n",
    "# Build and fit model\n",
    "series = monthly[\"price\"].asfreq(\"M\")\n",
    "model = ARIMA(series, order=(1,1,1))\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "# Forecast next 1 month\n",
    "n_steps = 1\n",
    "forecast_res = results.get_forecast(steps=n_steps)\n",
    "forecast_mean = forecast_res.predicted_mean\n",
    "forecast_ci = forecast_res.conf_int(alpha=0.05)\n",
    "\n",
    "next_month = forecast_mean.index[-1]\n",
    "print(f\"Next month forecast date: {next_month.date()} value: {forecast_mean.iloc[-1]:.4f}\")\n",
    "print(f\"95% CI: [{forecast_ci.iloc[-1,0]:.4f}, {forecast_ci.iloc[-1,1]:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot historical and forecast\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "series.plot(ax=ax, label=\"History\")\n",
    "forecast_mean.plot(ax=ax, style=\"r--\", label=\"Forecast\")\n",
    "ax.fill_between(forecast_ci.index, forecast_ci.iloc[:,0], forecast_ci.iloc[:,1], color=\"r\", alpha=0.2, label=\"95% CI\")\n",
    "ax.set_title(f\"ARIMA(1,1,1) forecast for {chosen_id}\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Price\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
