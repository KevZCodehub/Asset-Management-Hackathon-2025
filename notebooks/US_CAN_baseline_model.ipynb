{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28616a8f",
   "metadata": {},
   "source": [
    "# Baseline Models (Optimized US_CAN)\n",
    "\n",
    "This notebook implements efficient baseline models (OLS, Exponential Smoothing, XGBoost) using an expanding window. It uses the shared data loader and the hackathon datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d30af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bn/cx_ppcpx0ngbpf4h354g9_k80000gn/T/ipykernel_77909/2243707995.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2025-09-24 17:39:33.975993\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from math import sqrt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Use shared data loader\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "from data_loader import load_data\n",
    "\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d68f93ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading data from: /Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/data/usa_can_filtered_data.csv\n",
      "Loading data from: /Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/data/factor_char_list.csv\n",
      "Data shape after filter: (1398807, 159)\n",
      "Date range: 2005-02-28 00:00:00 to 2025-06-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Load data using the shared data loader\n",
    "print(\"Loading data...\")\n",
    "raw = load_data(filename=\"usa_can_filtered_data.csv\", parse_dates=[\"ret_eom\"], low_memory=False)\n",
    "raw['date'] = pd.to_datetime(raw['ret_eom'])\n",
    "\n",
    "# Load predictor list\n",
    "stock_vars = list(load_data(filename=\"factor_char_list.csv\")[\"variable\"].values)\n",
    "ret_var = \"stock_ret\"\n",
    "\n",
    "# Keep only valid target rows\n",
    "raw = raw[raw[ret_var].notna()].copy()\n",
    "print(f\"Data shape after filter: {raw.shape}\")\n",
    "print(f\"Date range: {raw['date'].min()} to {raw['date'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60e6f77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying vectorized cross-sectional rank scaling...\n",
      "Scaled data shape: (1398807, 159)\n"
     ]
    }
   ],
   "source": [
    "# Vectorized cross-sectional rank scaling by date (efficient)\n",
    "print(\"Applying vectorized cross-sectional rank scaling...\")\n",
    "\n",
    "data = raw.copy()\n",
    "for var in stock_vars:\n",
    "    if var not in data.columns:\n",
    "        continue\n",
    "    med = data.groupby('date')[var].transform('median')\n",
    "    data[var] = data[var].fillna(med)\n",
    "\n",
    "    ranks = data.groupby('date')[var].rank(method='dense') - 1\n",
    "    maxs = data.groupby('date')[var].transform('max')\n",
    "    data[var] = np.where(maxs > 0, (ranks / maxs) * 2 - 1, 0)\n",
    "\n",
    "del raw\n",
    "print(f\"Scaled data shape: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3389c40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available dates: 2005-02-28T00:00:00.000000000 to 2025-06-30T00:00:00.000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's rmse: 0.182909\tvalid_0's l2: 0.0334559\n",
      "Finished period 1: 2005-01-01 -> 2016-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's rmse: 15.1068\tvalid_0's l2: 228.217\n",
      "Finished period 2: 2005-01-01 -> 2017-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's rmse: 15.2389\tvalid_0's l2: 232.225\n",
      "Finished period 3: 2005-01-01 -> 2018-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 26.8074\tvalid_0's l2: 718.636\n",
      "Finished period 4: 2005-01-01 -> 2019-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's rmse: 27.0653\tvalid_0's l2: 732.531\n",
      "Finished period 5: 2005-01-01 -> 2020-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 1.24481\tvalid_0's l2: 1.54954\n",
      "Finished period 6: 2005-01-01 -> 2021-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.307975\tvalid_0's l2: 0.0948484\n",
      "Finished period 7: 2005-01-01 -> 2022-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.398054\tvalid_0's l2: 0.158447\n",
      "Finished period 8: 2005-01-01 -> 2023-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.355366\tvalid_0's l2: 0.126285\n",
      "Finished period 9: 2005-01-01 -> 2024-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.351247\tvalid_0's l2: 0.123374\n",
      "Finished period 10: 2005-01-01 -> 2025-01-01\n",
      "Total periods processed: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Pre-calc unique dates to bound the loop\n",
    "unique_dates = np.sort(data['date'].unique())\n",
    "end_bound = unique_dates[-1]\n",
    "print(f\"Available dates: {unique_dates[0]} to {end_bound}\")\n",
    "\n",
    "# Expanding window setup\n",
    "starting = pd.to_datetime(\"20050101\", format=\"%Y%m%d\")\n",
    "counter = 0\n",
    "results_rows = []\n",
    "feature_rows = []\n",
    "\n",
    "while (starting + pd.DateOffset(years=11 + counter)) <= end_bound:\n",
    "    cutoff = [\n",
    "        starting,\n",
    "        starting + pd.DateOffset(years=8 + counter),\n",
    "        starting + pd.DateOffset(years=10 + counter),\n",
    "        starting + pd.DateOffset(years=11 + counter),\n",
    "    ]\n",
    "\n",
    "    train = data[(data[\"date\"] >= cutoff[0]) & (data[\"date\"] < cutoff[1])]\n",
    "    validate = data[(data[\"date\"] >= cutoff[1]) & (data[\"date\"] < cutoff[2])]\n",
    "    test = data[(data[\"date\"] >= cutoff[2]) & (data[\"date\"] < cutoff[3])]\n",
    "\n",
    "    if len(train) == 0 or len(validate) == 0 or len(test) == 0:\n",
    "        print(f\"Skipping period {counter+1}: insufficient data\")\n",
    "        counter += 1\n",
    "        continue\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler().fit(train[stock_vars])\n",
    "    X_train = scaler.transform(train[stock_vars])\n",
    "    X_val   = scaler.transform(validate[stock_vars])\n",
    "    X_test  = scaler.transform(test[stock_vars])\n",
    "\n",
    "    Y_train = train[ret_var].values\n",
    "    Y_val   = validate[ret_var].values\n",
    "    Y_test  = test[ret_var].values\n",
    "\n",
    "    # Prepare OOF frame for predictions\n",
    "    fold_df = test[[\"year\", \"month\", \"date\", \"id\", ret_var]].copy()\n",
    "\n",
    "    # --- LINEAR REGRESSION ---\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, Y_train)\n",
    "    fold_df[\"ols\"] = lr.predict(X_test)\n",
    "\n",
    "    # Store top 25 features for OLS\n",
    "    coef_abs = np.abs(lr.coef_)\n",
    "    top_idx = np.argsort(coef_abs)[-25:][::-1]  # descending\n",
    "    for idx in top_idx:\n",
    "        feature_rows.append({\n",
    "            \"eval_year\": cutoff[2].year,\n",
    "            \"model\": \"ols\",\n",
    "            \"feature\": stock_vars[idx],\n",
    "            \"importance\": lr.coef_[idx]\n",
    "        })\n",
    "\n",
    "    # --- EXPONENTIAL SMOOTHING ---\n",
    "    try:\n",
    "        ts = train.groupby(\"date\")[ret_var].mean().sort_index()\n",
    "        model = ExponentialSmoothing(ts, trend=\"add\", seasonal=None).fit()\n",
    "        dates_test = sorted(test[\"date\"].unique())\n",
    "        forecast = model.forecast(len(dates_test))\n",
    "        forecast_map = dict(zip(dates_test, forecast))\n",
    "        fold_df[\"exp_smooth\"] = test[\"date\"].map(forecast_map)\n",
    "        # Feature importance not applicable for this model\n",
    "    except Exception as e:\n",
    "        print(\"Exponential Smoothing failed:\", e)\n",
    "        fold_df[\"exp_smooth\"] = np.nan\n",
    "\n",
    "    # --- XGBOOST ---\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    xgb.fit(X_train, Y_train, eval_set=[(X_val, Y_val)], early_stopping_rounds=20, verbose=False)\n",
    "    fold_df[\"xgb\"] = xgb.predict(X_test)\n",
    "\n",
    "    # Store top 25 features for XGBoost\n",
    "    importance_abs = np.abs(xgb.feature_importances_)\n",
    "    top_idx = np.argsort(importance_abs)[-25:][::-1]\n",
    "    for idx in top_idx:\n",
    "        feature_rows.append({\n",
    "            \"eval_year\": cutoff[2].year,\n",
    "            \"model\": \"xgb\",\n",
    "            \"feature\": stock_vars[idx],\n",
    "            \"importance\": xgb.feature_importances_[idx]\n",
    "        })\n",
    "\n",
    "    # --- LIGHTGBM ---\n",
    "    lgbm = LGBMRegressor(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=-1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1   # silence completely\n",
    "    )\n",
    "    lgbm.fit(\n",
    "        X_train, Y_train,\n",
    "        eval_set=[(X_val, Y_val)],\n",
    "        eval_metric=\"rmse\",\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=20),\n",
    "            log_evaluation(-1)  # disable logging\n",
    "        ]\n",
    "    )\n",
    "    fold_df[\"lgbm\"] = lgbm.predict(X_test)\n",
    "\n",
    "    # Store top 25 features for LightGBM\n",
    "    importance_abs = np.abs(lgbm.feature_importances_)\n",
    "    top_idx = np.argsort(importance_abs)[-25:][::-1]\n",
    "    for idx in top_idx:\n",
    "        feature_rows.append({\n",
    "            \"eval_year\": cutoff[2].year,\n",
    "            \"model\": \"lgbm\",\n",
    "            \"feature\": stock_vars[idx],\n",
    "            \"importance\": lgbm.feature_importances_[idx]\n",
    "        })\n",
    "\n",
    "        # --- METRICS ---\n",
    "    for model_name in [\"ols\", \"exp_smooth\", \"xgb\", \"lgbm\"]:\n",
    "        y_pred = fold_df[model_name].values\n",
    "        rmse = sqrt(mean_squared_error(Y_test, y_pred))\n",
    "        mae = mean_absolute_error(Y_test, y_pred)\n",
    "        r2 = r2_score(Y_test, y_pred)\n",
    "\n",
    "        # Spearman correlation (Information Coefficient, IC)\n",
    "        try:\n",
    "            ic, _ = spearmanr(Y_test, y_pred)\n",
    "        except Exception:\n",
    "            ic = np.nan\n",
    "\n",
    "        # --- Portfolio backtest (equal-weight long/short 125 each side) ---\n",
    "        port_return = np.nan\n",
    "        if fold_df.shape[0] >= 250:\n",
    "            temp = fold_df.copy()\n",
    "            temp[\"pred\"] = y_pred\n",
    "\n",
    "            longs = temp.nlargest(125, \"pred\")\n",
    "            shorts = temp.nsmallest(125, \"pred\")\n",
    "\n",
    "            # Equal weight: mean of realized returns\n",
    "            long_ret = longs[ret_var].mean()\n",
    "            short_ret = shorts[ret_var].mean()\n",
    "            port_return = long_ret - short_ret\n",
    "\n",
    "        results_rows.append({\n",
    "            \"eval_year\": cutoff[2].year,\n",
    "            \"model\": model_name,\n",
    "            \"rmse\": float(rmse),\n",
    "            \"mae\": float(mae),\n",
    "            \"r2\": float(r2),\n",
    "            \"ic\": float(ic) if ic is not None else np.nan,\n",
    "            \"portfolio_return\": float(port_return) if port_return is not None else np.nan,\n",
    "        })\n",
    "\n",
    "    print(f\"Finished period {counter+1}: {cutoff[0].date()} -> {cutoff[3].date()}\")\n",
    "    counter += 1\n",
    "\n",
    "print(f\"Total periods processed: {counter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "510e8b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to: /Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/data/results_can_usa_baselines.csv\n",
      "Saved top features to: /Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/data/feature_can_usa_importances.csv\n",
      "2025-09-24 17:44:30.241551\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "results_df = pd.DataFrame(results_rows)\n",
    "output_path = Path.cwd().parent / \"data\" / \"results_can_usa_baselines.csv\"\n",
    "results_df.to_csv(output_path, index=False)\n",
    "print(f\"Saved results to: {output_path}\")\n",
    "\n",
    "# Save feature importances\n",
    "feature_df = pd.DataFrame(feature_rows)\n",
    "feature_df.sort_values([\"eval_year\", \"model\", \"importance\"], ascending=[True, True, False], inplace=True)\n",
    "output_features_path = Path.cwd().parent / \"data\" / \"feature_can_usa_importances.csv\"\n",
    "feature_df.to_csv(output_features_path, index=False)\n",
    "print(f\"Saved top features to: {output_features_path}\")\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78f6e934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_year</th>\n",
       "      <th>model</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "      <th>ic</th>\n",
       "      <th>portfolio_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>ols</td>\n",
       "      <td>21.370326</td>\n",
       "      <td>0.203618</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.008591</td>\n",
       "      <td>-0.023363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>21.370389</td>\n",
       "      <td>0.193131</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.066059</td>\n",
       "      <td>0.015276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>xgb</td>\n",
       "      <td>21.369251</td>\n",
       "      <td>0.247527</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.052647</td>\n",
       "      <td>44.841345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>21.368590</td>\n",
       "      <td>0.194507</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.024719</td>\n",
       "      <td>44.126969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>ols</td>\n",
       "      <td>0.232696</td>\n",
       "      <td>0.129316</td>\n",
       "      <td>-0.042111</td>\n",
       "      <td>0.109864</td>\n",
       "      <td>0.101981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>0.227946</td>\n",
       "      <td>0.113641</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.046604</td>\n",
       "      <td>0.083197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>xgb</td>\n",
       "      <td>1.580551</td>\n",
       "      <td>0.129007</td>\n",
       "      <td>-47.078673</td>\n",
       "      <td>0.105857</td>\n",
       "      <td>0.249065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.227266</td>\n",
       "      <td>0.112985</td>\n",
       "      <td>0.005955</td>\n",
       "      <td>0.081062</td>\n",
       "      <td>0.298270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017</td>\n",
       "      <td>ols</td>\n",
       "      <td>38.167533</td>\n",
       "      <td>0.266772</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>-0.066963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>38.167635</td>\n",
       "      <td>0.246089</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.022715</td>\n",
       "      <td>0.033806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>xgb</td>\n",
       "      <td>38.167477</td>\n",
       "      <td>0.436922</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.085254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>38.167628</td>\n",
       "      <td>0.247846</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.007878</td>\n",
       "      <td>0.273724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018</td>\n",
       "      <td>ols</td>\n",
       "      <td>1.746377</td>\n",
       "      <td>0.194153</td>\n",
       "      <td>-0.009271</td>\n",
       "      <td>0.104070</td>\n",
       "      <td>-0.015574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>1.738821</td>\n",
       "      <td>0.116934</td>\n",
       "      <td>-0.000556</td>\n",
       "      <td>-0.198214</td>\n",
       "      <td>-0.071190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018</td>\n",
       "      <td>xgb</td>\n",
       "      <td>2.414581</td>\n",
       "      <td>0.466428</td>\n",
       "      <td>-0.929370</td>\n",
       "      <td>0.007492</td>\n",
       "      <td>3.436326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>1.743866</td>\n",
       "      <td>0.112409</td>\n",
       "      <td>-0.006371</td>\n",
       "      <td>0.026005</td>\n",
       "      <td>0.059502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>ols</td>\n",
       "      <td>0.243011</td>\n",
       "      <td>0.158158</td>\n",
       "      <td>-0.278297</td>\n",
       "      <td>0.099813</td>\n",
       "      <td>0.046051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>0.215395</td>\n",
       "      <td>0.113042</td>\n",
       "      <td>-0.004270</td>\n",
       "      <td>-0.077798</td>\n",
       "      <td>-0.055369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.395685</td>\n",
       "      <td>0.350619</td>\n",
       "      <td>-2.389058</td>\n",
       "      <td>0.043481</td>\n",
       "      <td>0.167062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.215480</td>\n",
       "      <td>0.111169</td>\n",
       "      <td>-0.005060</td>\n",
       "      <td>0.063001</td>\n",
       "      <td>0.152689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020</td>\n",
       "      <td>ols</td>\n",
       "      <td>0.307363</td>\n",
       "      <td>0.193439</td>\n",
       "      <td>-0.137460</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>-0.020362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>0.290977</td>\n",
       "      <td>0.171874</td>\n",
       "      <td>-0.019409</td>\n",
       "      <td>0.276031</td>\n",
       "      <td>0.136797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.505395</td>\n",
       "      <td>0.450945</td>\n",
       "      <td>-2.075352</td>\n",
       "      <td>0.148743</td>\n",
       "      <td>0.378016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.394319</td>\n",
       "      <td>0.164416</td>\n",
       "      <td>-0.872096</td>\n",
       "      <td>0.138070</td>\n",
       "      <td>0.158511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021</td>\n",
       "      <td>ols</td>\n",
       "      <td>0.259568</td>\n",
       "      <td>0.153271</td>\n",
       "      <td>-0.249134</td>\n",
       "      <td>0.028912</td>\n",
       "      <td>0.010903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>0.237096</td>\n",
       "      <td>0.123425</td>\n",
       "      <td>-0.042211</td>\n",
       "      <td>-0.156650</td>\n",
       "      <td>0.054631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021</td>\n",
       "      <td>xgb</td>\n",
       "      <td>2.943448</td>\n",
       "      <td>0.339742</td>\n",
       "      <td>-159.627262</td>\n",
       "      <td>-0.019555</td>\n",
       "      <td>0.005444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.460060</td>\n",
       "      <td>0.124822</td>\n",
       "      <td>-2.924065</td>\n",
       "      <td>-0.013809</td>\n",
       "      <td>-0.022059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2022</td>\n",
       "      <td>ols</td>\n",
       "      <td>0.378242</td>\n",
       "      <td>0.173578</td>\n",
       "      <td>-0.168477</td>\n",
       "      <td>0.032781</td>\n",
       "      <td>0.019207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2022</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>0.358276</td>\n",
       "      <td>0.143170</td>\n",
       "      <td>-0.048371</td>\n",
       "      <td>0.058062</td>\n",
       "      <td>-0.022801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2022</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.939620</td>\n",
       "      <td>0.513479</td>\n",
       "      <td>-6.210820</td>\n",
       "      <td>-0.052646</td>\n",
       "      <td>0.033392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2022</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.452021</td>\n",
       "      <td>0.136351</td>\n",
       "      <td>-0.668777</td>\n",
       "      <td>-0.055945</td>\n",
       "      <td>0.106703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023</td>\n",
       "      <td>ols</td>\n",
       "      <td>0.292208</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>-0.321063</td>\n",
       "      <td>-0.046849</td>\n",
       "      <td>-0.071766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>0.258098</td>\n",
       "      <td>0.144362</td>\n",
       "      <td>-0.030649</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>-0.031403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2023</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.477467</td>\n",
       "      <td>0.426987</td>\n",
       "      <td>-2.527174</td>\n",
       "      <td>-0.171397</td>\n",
       "      <td>-0.232120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2023</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.256906</td>\n",
       "      <td>0.136841</td>\n",
       "      <td>-0.021150</td>\n",
       "      <td>-0.132170</td>\n",
       "      <td>0.004072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024</td>\n",
       "      <td>ols</td>\n",
       "      <td>0.359401</td>\n",
       "      <td>0.165145</td>\n",
       "      <td>-0.069543</td>\n",
       "      <td>0.041193</td>\n",
       "      <td>0.028406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2024</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>0.349647</td>\n",
       "      <td>0.144049</td>\n",
       "      <td>-0.012276</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>-0.043090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2024</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.829259</td>\n",
       "      <td>0.400389</td>\n",
       "      <td>-4.694034</td>\n",
       "      <td>-0.035640</td>\n",
       "      <td>0.048693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2024</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.439316</td>\n",
       "      <td>0.141793</td>\n",
       "      <td>-0.598064</td>\n",
       "      <td>-0.072102</td>\n",
       "      <td>-0.022545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eval_year       model       rmse       mae          r2        ic  \\\n",
       "0        2015         ols  21.370326  0.203618   -0.000005 -0.008591   \n",
       "1        2015  exp_smooth  21.370389  0.193131   -0.000011  0.066059   \n",
       "2        2015         xgb  21.369251  0.247527    0.000095  0.052647   \n",
       "3        2015        lgbm  21.368590  0.194507    0.000157  0.024719   \n",
       "4        2016         ols   0.232696  0.129316   -0.042111  0.109864   \n",
       "5        2016  exp_smooth   0.227946  0.113641    0.000003  0.046604   \n",
       "6        2016         xgb   1.580551  0.129007  -47.078673  0.105857   \n",
       "7        2016        lgbm   0.227266  0.112985    0.005955  0.081062   \n",
       "8        2017         ols  38.167533  0.266772   -0.000015 -0.000165   \n",
       "9        2017  exp_smooth  38.167635  0.246089   -0.000020 -0.022715   \n",
       "10       2017         xgb  38.167477  0.436922   -0.000012  0.003181   \n",
       "11       2017        lgbm  38.167628  0.247846   -0.000019 -0.007878   \n",
       "12       2018         ols   1.746377  0.194153   -0.009271  0.104070   \n",
       "13       2018  exp_smooth   1.738821  0.116934   -0.000556 -0.198214   \n",
       "14       2018         xgb   2.414581  0.466428   -0.929370  0.007492   \n",
       "15       2018        lgbm   1.743866  0.112409   -0.006371  0.026005   \n",
       "16       2019         ols   0.243011  0.158158   -0.278297  0.099813   \n",
       "17       2019  exp_smooth   0.215395  0.113042   -0.004270 -0.077798   \n",
       "18       2019         xgb   0.395685  0.350619   -2.389058  0.043481   \n",
       "19       2019        lgbm   0.215480  0.111169   -0.005060  0.063001   \n",
       "20       2020         ols   0.307363  0.193439   -0.137460  0.007965   \n",
       "21       2020  exp_smooth   0.290977  0.171874   -0.019409  0.276031   \n",
       "22       2020         xgb   0.505395  0.450945   -2.075352  0.148743   \n",
       "23       2020        lgbm   0.394319  0.164416   -0.872096  0.138070   \n",
       "24       2021         ols   0.259568  0.153271   -0.249134  0.028912   \n",
       "25       2021  exp_smooth   0.237096  0.123425   -0.042211 -0.156650   \n",
       "26       2021         xgb   2.943448  0.339742 -159.627262 -0.019555   \n",
       "27       2021        lgbm   0.460060  0.124822   -2.924065 -0.013809   \n",
       "28       2022         ols   0.378242  0.173578   -0.168477  0.032781   \n",
       "29       2022  exp_smooth   0.358276  0.143170   -0.048371  0.058062   \n",
       "30       2022         xgb   0.939620  0.513479   -6.210820 -0.052646   \n",
       "31       2022        lgbm   0.452021  0.136351   -0.668777 -0.055945   \n",
       "32       2023         ols   0.292208  0.192700   -0.321063 -0.046849   \n",
       "33       2023  exp_smooth   0.258098  0.144362   -0.030649  0.007570   \n",
       "34       2023         xgb   0.477467  0.426987   -2.527174 -0.171397   \n",
       "35       2023        lgbm   0.256906  0.136841   -0.021150 -0.132170   \n",
       "36       2024         ols   0.359401  0.165145   -0.069543  0.041193   \n",
       "37       2024  exp_smooth   0.349647  0.144049   -0.012276  0.001474   \n",
       "38       2024         xgb   0.829259  0.400389   -4.694034 -0.035640   \n",
       "39       2024        lgbm   0.439316  0.141793   -0.598064 -0.072102   \n",
       "\n",
       "    portfolio_return  \n",
       "0          -0.023363  \n",
       "1           0.015276  \n",
       "2          44.841345  \n",
       "3          44.126969  \n",
       "4           0.101981  \n",
       "5           0.083197  \n",
       "6           0.249065  \n",
       "7           0.298270  \n",
       "8          -0.066963  \n",
       "9           0.033806  \n",
       "10          0.085254  \n",
       "11          0.273724  \n",
       "12         -0.015574  \n",
       "13         -0.071190  \n",
       "14          3.436326  \n",
       "15          0.059502  \n",
       "16          0.046051  \n",
       "17         -0.055369  \n",
       "18          0.167062  \n",
       "19          0.152689  \n",
       "20         -0.020362  \n",
       "21          0.136797  \n",
       "22          0.378016  \n",
       "23          0.158511  \n",
       "24          0.010903  \n",
       "25          0.054631  \n",
       "26          0.005444  \n",
       "27         -0.022059  \n",
       "28          0.019207  \n",
       "29         -0.022801  \n",
       "30          0.033392  \n",
       "31          0.106703  \n",
       "32         -0.071766  \n",
       "33         -0.031403  \n",
       "34         -0.232120  \n",
       "35          0.004072  \n",
       "36          0.028406  \n",
       "37         -0.043090  \n",
       "38          0.048693  \n",
       "39         -0.022545  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64a15075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_year</th>\n",
       "      <th>model</th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2015</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>dolvol_126d</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>prc</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2015</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>market_equity</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2015</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>ebitda_mev</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2015</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>bev_mev</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>2024</td>\n",
       "      <td>xgb</td>\n",
       "      <td>ni_me</td>\n",
       "      <td>0.000629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>2024</td>\n",
       "      <td>xgb</td>\n",
       "      <td>aliq_mat</td>\n",
       "      <td>0.000603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>2024</td>\n",
       "      <td>xgb</td>\n",
       "      <td>niq_su</td>\n",
       "      <td>0.000524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>2024</td>\n",
       "      <td>xgb</td>\n",
       "      <td>at_me</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>2024</td>\n",
       "      <td>xgb</td>\n",
       "      <td>capx_gr1</td>\n",
       "      <td>0.000374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     eval_year model        feature  importance\n",
       "50        2015  lgbm    dolvol_126d   11.000000\n",
       "51        2015  lgbm            prc   11.000000\n",
       "52        2015  lgbm  market_equity    9.000000\n",
       "53        2015  lgbm     ebitda_mev    8.000000\n",
       "54        2015  lgbm        bev_mev    7.000000\n",
       "..         ...   ...            ...         ...\n",
       "720       2024   xgb          ni_me    0.000629\n",
       "721       2024   xgb       aliq_mat    0.000603\n",
       "722       2024   xgb         niq_su    0.000524\n",
       "723       2024   xgb          at_me    0.000434\n",
       "724       2024   xgb       capx_gr1    0.000374\n",
       "\n",
       "[750 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b149d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts = (\n",
    "    feature_df.groupby([\"model\", \"feature\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values([\"model\", \"count\"], ascending=[True, False])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d3db259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>feature</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>xgb</td>\n",
       "      <td>age</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>xgb</td>\n",
       "      <td>aliq_mat</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>xgb</td>\n",
       "      <td>niq_be</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>xgb</td>\n",
       "      <td>aliq_at</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>xgb</td>\n",
       "      <td>bidaskhl_21d</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>xgb</td>\n",
       "      <td>cop_at</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>xgb</td>\n",
       "      <td>dolvol_126d</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>xgb</td>\n",
       "      <td>turnover_var_126d</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>xgb</td>\n",
       "      <td>coskew_21d</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>xgb</td>\n",
       "      <td>lti_gr1a</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>xgb</td>\n",
       "      <td>ni_me</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>xgb</td>\n",
       "      <td>prc</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>xgb</td>\n",
       "      <td>ret_1_0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>xgb</td>\n",
       "      <td>dgp_dsale</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>xgb</td>\n",
       "      <td>f_score</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model            feature  count\n",
       "143   xgb                age     10\n",
       "145   xgb           aliq_mat     10\n",
       "190   xgb             niq_be      9\n",
       "144   xgb            aliq_at      8\n",
       "155   xgb       bidaskhl_21d      8\n",
       "159   xgb             cop_at      8\n",
       "164   xgb        dolvol_126d      8\n",
       "213   xgb  turnover_var_126d      8\n",
       "161   xgb         coskew_21d      7\n",
       "181   xgb           lti_gr1a      7\n",
       "189   xgb              ni_me      7\n",
       "199   xgb                prc      7\n",
       "203   xgb            ret_1_0      7\n",
       "163   xgb          dgp_dsale      6\n",
       "174   xgb            f_score      6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(feature_counts[feature_counts[\"model\"] == \"xgb\"]).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42527613-92ab-4c0e-8a24-b2d52b119019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
