{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models (Optimized)\n",
    "\n",
    "This notebook implements efficient baseline models (OLS, Exponential Smoothing, XGBoost) using an expanding window. It uses the shared data loader and the hackathon datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bn/cx_ppcpx0ngbpf4h354g9_k80000gn/T/ipykernel_71099/320859749.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2025-09-22 14:11:15.048345\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Use shared data loader\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "from data_loader import load_data\n",
    "\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading data from: /Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/data/ret_sample.csv\n",
      "Loading data from: /Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/data/factor_char_list.csv\n",
      "Data shape after filter: (6401414, 159)\n",
      "Date range: 2005-02-28 00:00:00 to 2025-06-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Load data using the shared data loader\n",
    "print(\"Loading data...\")\n",
    "raw = load_data(filename=\"ret_sample.csv\", parse_dates=[\"ret_eom\"], low_memory=False)\n",
    "raw['date'] = pd.to_datetime(raw['ret_eom'])\n",
    "\n",
    "# Load predictor list\n",
    "stock_vars = list(load_data(filename=\"factor_char_list.csv\")[\"variable\"].values)\n",
    "ret_var = \"stock_ret\"\n",
    "\n",
    "# Keep only valid target rows\n",
    "raw = raw[raw[ret_var].notna()].copy()\n",
    "print(f\"Data shape after filter: {raw.shape}\")\n",
    "print(f\"Date range: {raw['date'].min()} to {raw['date'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying vectorized cross-sectional rank scaling...\n",
      "Scaled data shape: (6401414, 159)\n"
     ]
    }
   ],
   "source": [
    "# Vectorized cross-sectional rank scaling by date (efficient)\n",
    "print(\"Applying vectorized cross-sectional rank scaling...\")\n",
    "\n",
    "data = raw.copy()\n",
    "for var in stock_vars:\n",
    "    if var not in data.columns:\n",
    "        continue\n",
    "    med = data.groupby('date')[var].transform('median')\n",
    "    data[var] = data[var].fillna(med)\n",
    "\n",
    "    ranks = data.groupby('date')[var].rank(method='dense') - 1\n",
    "    maxs = data.groupby('date')[var].transform('max')\n",
    "    data[var] = np.where(maxs > 0, (ranks / maxs) * 2 - 1, 0)\n",
    "\n",
    "del raw\n",
    "print(f\"Scaled data shape: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available dates: 2005-02-28T00:00:00.000000000 to 2025-06-30T00:00:00.000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished period 1: 2005-01-01 -> 2016-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished period 2: 2005-01-01 -> 2017-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished period 3: 2005-01-01 -> 2018-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished period 4: 2005-01-01 -> 2019-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished period 5: 2005-01-01 -> 2020-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished period 6: 2005-01-01 -> 2021-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished period 7: 2005-01-01 -> 2022-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished period 8: 2005-01-01 -> 2023-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished period 9: 2005-01-01 -> 2024-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ME will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/venv/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished period 10: 2005-01-01 -> 2025-01-01\n",
      "Total periods processed: 10\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# Pre-calc unique dates to bound the loop\n",
    "unique_dates = np.sort(data['date'].unique())\n",
    "end_bound = unique_dates[-1]\n",
    "print(f\"Available dates: {unique_dates[0]} to {end_bound}\")\n",
    "\n",
    "# Expanding window setup\n",
    "starting = pd.to_datetime(\"20050101\", format=\"%Y%m%d\")\n",
    "counter = 0\n",
    "results_rows = []\n",
    "feature_rows = []\n",
    "\n",
    "while (starting + pd.DateOffset(years=11 + counter)) <= end_bound:\n",
    "    cutoff = [\n",
    "        starting,\n",
    "        starting + pd.DateOffset(years=8 + counter),\n",
    "        starting + pd.DateOffset(years=10 + counter),\n",
    "        starting + pd.DateOffset(years=11 + counter),\n",
    "    ]\n",
    "\n",
    "    train = data[(data[\"date\"] >= cutoff[0]) & (data[\"date\"] < cutoff[1])]\n",
    "    validate = data[(data[\"date\"] >= cutoff[1]) & (data[\"date\"] < cutoff[2])]\n",
    "    test = data[(data[\"date\"] >= cutoff[2]) & (data[\"date\"] < cutoff[3])]\n",
    "\n",
    "    if len(train) == 0 or len(validate) == 0 or len(test) == 0:\n",
    "        print(f\"Skipping period {counter+1}: insufficient data\")\n",
    "        counter += 1\n",
    "        continue\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler().fit(train[stock_vars])\n",
    "    X_train = scaler.transform(train[stock_vars])\n",
    "    X_val   = scaler.transform(validate[stock_vars])\n",
    "    X_test  = scaler.transform(test[stock_vars])\n",
    "\n",
    "    Y_train = train[ret_var].values\n",
    "    Y_val   = validate[ret_var].values\n",
    "    Y_test  = test[ret_var].values\n",
    "\n",
    "    # Prepare OOF frame for predictions\n",
    "    fold_df = test[[\"year\", \"month\", \"date\", \"id\", ret_var]].copy()\n",
    "\n",
    "    # --- LINEAR REGRESSION ---\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, Y_train)\n",
    "    fold_df[\"ols\"] = lr.predict(X_test)\n",
    "\n",
    "    # Store top 25 features for OLS\n",
    "    coef_abs = np.abs(lr.coef_)\n",
    "    top_idx = np.argsort(coef_abs)[-25:][::-1]  # descending\n",
    "    for idx in top_idx:\n",
    "        feature_rows.append({\n",
    "            \"eval_year\": cutoff[2].year,\n",
    "            \"model\": \"ols\",\n",
    "            \"feature\": stock_vars[idx],\n",
    "            \"importance\": lr.coef_[idx]\n",
    "        })\n",
    "\n",
    "    # --- EXPONENTIAL SMOOTHING ---\n",
    "    try:\n",
    "        ts = train.groupby(\"date\")[ret_var].mean().sort_index()\n",
    "        model = ExponentialSmoothing(ts, trend=\"add\", seasonal=None).fit()\n",
    "        dates_test = sorted(test[\"date\"].unique())\n",
    "        forecast = model.forecast(len(dates_test))\n",
    "        forecast_map = dict(zip(dates_test, forecast))\n",
    "        fold_df[\"exp_smooth\"] = test[\"date\"].map(forecast_map)\n",
    "        # Feature importance not applicable for this model\n",
    "    except Exception as e:\n",
    "        print(\"Exponential Smoothing failed:\", e)\n",
    "        fold_df[\"exp_smooth\"] = np.nan\n",
    "\n",
    "    # --- XGBOOST ---\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    xgb.fit(X_train, Y_train, eval_set=[(X_val, Y_val)], early_stopping_rounds=20, verbose=False)\n",
    "    fold_df[\"xgb\"] = xgb.predict(X_test)\n",
    "\n",
    "    # Store top 25 features for XGBoost\n",
    "    importance_abs = np.abs(xgb.feature_importances_)\n",
    "    top_idx = np.argsort(importance_abs)[-25:][::-1]\n",
    "    for idx in top_idx:\n",
    "        feature_rows.append({\n",
    "            \"eval_year\": cutoff[2].year,\n",
    "            \"model\": \"xgb\",\n",
    "            \"feature\": stock_vars[idx],\n",
    "            \"importance\": xgb.feature_importances_[idx]\n",
    "        })\n",
    "\n",
    "    # --- METRICS ---\n",
    "    for model_name in [\"ols\", \"exp_smooth\", \"xgb\"]:\n",
    "        y_pred = fold_df[model_name].values\n",
    "        rmse = sqrt(mean_squared_error(Y_test, y_pred))\n",
    "        mape = mean_absolute_percentage_error(Y_test, y_pred)\n",
    "        results_rows.append({\n",
    "            \"eval_year\": cutoff[2].year,\n",
    "            \"model\": model_name,\n",
    "            \"rmse\": float(rmse),\n",
    "            \"mape\": float(mape),\n",
    "        })\n",
    "\n",
    "    print(f\"Finished period {counter+1}: {cutoff[0].date()} -> {cutoff[3].date()}\")\n",
    "    counter += 1\n",
    "\n",
    "print(f\"Total periods processed: {counter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to: /Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/data/results_baselines.csv\n",
      "Saved top features to: /Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/data/feature_importances.csv\n",
      "2025-09-22 14:58:16.522173\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "results_df = pd.DataFrame(results_rows)\n",
    "output_path = Path.cwd().parent / \"data\" / \"results_baselines.csv\"\n",
    "results_df.to_csv(output_path, index=False)\n",
    "print(f\"Saved results to: {output_path}\")\n",
    "\n",
    "# Save feature importances\n",
    "feature_df = pd.DataFrame(feature_rows)\n",
    "feature_df.sort_values([\"eval_year\", \"model\", \"importance\"], ascending=[True, True, False], inplace=True)\n",
    "output_features_path = Path.cwd().parent / \"data\" / \"feature_importances.csv\"\n",
    "feature_df.to_csv(output_features_path, index=False)\n",
    "print(f\"Saved top features to: {output_features_path}\")\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_year</th>\n",
       "      <th>model</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>ols</td>\n",
       "      <td>10.008084</td>\n",
       "      <td>2.548813e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>10.007880</td>\n",
       "      <td>1.036985e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>xgb</td>\n",
       "      <td>10.007238</td>\n",
       "      <td>7.861817e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>ols</td>\n",
       "      <td>0.236610</td>\n",
       "      <td>2.446240e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>0.228054</td>\n",
       "      <td>1.269578e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.295283</td>\n",
       "      <td>5.947668e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017</td>\n",
       "      <td>ols</td>\n",
       "      <td>17.019633</td>\n",
       "      <td>2.136179e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>17.019600</td>\n",
       "      <td>7.075213e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017</td>\n",
       "      <td>xgb</td>\n",
       "      <td>17.020221</td>\n",
       "      <td>1.697768e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018</td>\n",
       "      <td>ols</td>\n",
       "      <td>1.468385</td>\n",
       "      <td>2.776720e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>1.467647</td>\n",
       "      <td>7.272879e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018</td>\n",
       "      <td>xgb</td>\n",
       "      <td>2.355852</td>\n",
       "      <td>1.495575e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019</td>\n",
       "      <td>ols</td>\n",
       "      <td>4.456947</td>\n",
       "      <td>4.648107e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>4.456644</td>\n",
       "      <td>1.083104e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019</td>\n",
       "      <td>xgb</td>\n",
       "      <td>4.471133</td>\n",
       "      <td>2.573538e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020</td>\n",
       "      <td>ols</td>\n",
       "      <td>0.675545</td>\n",
       "      <td>3.429481e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>0.668279</td>\n",
       "      <td>9.876889e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.734757</td>\n",
       "      <td>1.159793e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021</td>\n",
       "      <td>ols</td>\n",
       "      <td>64.518302</td>\n",
       "      <td>5.428255e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>64.518418</td>\n",
       "      <td>1.260170e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021</td>\n",
       "      <td>xgb</td>\n",
       "      <td>64.519240</td>\n",
       "      <td>1.885854e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022</td>\n",
       "      <td>ols</td>\n",
       "      <td>47.870117</td>\n",
       "      <td>2.646056e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>47.870075</td>\n",
       "      <td>1.595314e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2022</td>\n",
       "      <td>xgb</td>\n",
       "      <td>47.876796</td>\n",
       "      <td>3.643396e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023</td>\n",
       "      <td>ols</td>\n",
       "      <td>15.139311</td>\n",
       "      <td>2.447663e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>15.139361</td>\n",
       "      <td>1.063955e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023</td>\n",
       "      <td>xgb</td>\n",
       "      <td>15.157966</td>\n",
       "      <td>2.091417e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2024</td>\n",
       "      <td>ols</td>\n",
       "      <td>28.058081</td>\n",
       "      <td>4.834143e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2024</td>\n",
       "      <td>exp_smooth</td>\n",
       "      <td>28.058014</td>\n",
       "      <td>2.247528e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2024</td>\n",
       "      <td>xgb</td>\n",
       "      <td>28.075434</td>\n",
       "      <td>2.115471e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eval_year       model       rmse          mape\n",
       "0        2015         ols  10.008084  2.548813e+11\n",
       "1        2015  exp_smooth  10.007880  1.036985e+11\n",
       "2        2015         xgb  10.007238  7.861817e+11\n",
       "3        2016         ols   0.236610  2.446240e+11\n",
       "4        2016  exp_smooth   0.228054  1.269578e+11\n",
       "5        2016         xgb   0.295283  5.947668e+11\n",
       "6        2017         ols  17.019633  2.136179e+11\n",
       "7        2017  exp_smooth  17.019600  7.075213e+10\n",
       "8        2017         xgb  17.020221  1.697768e+11\n",
       "9        2018         ols   1.468385  2.776720e+11\n",
       "10       2018  exp_smooth   1.467647  7.272879e+10\n",
       "11       2018         xgb   2.355852  1.495575e+12\n",
       "12       2019         ols   4.456947  4.648107e+11\n",
       "13       2019  exp_smooth   4.456644  1.083104e+11\n",
       "14       2019         xgb   4.471133  2.573538e+12\n",
       "15       2020         ols   0.675545  3.429481e+11\n",
       "16       2020  exp_smooth   0.668279  9.876889e+10\n",
       "17       2020         xgb   0.734757  1.159793e+12\n",
       "18       2021         ols  64.518302  5.428255e+11\n",
       "19       2021  exp_smooth  64.518418  1.260170e+11\n",
       "20       2021         xgb  64.519240  1.885854e+12\n",
       "21       2022         ols  47.870117  2.646056e+11\n",
       "22       2022  exp_smooth  47.870075  1.595314e+11\n",
       "23       2022         xgb  47.876796  3.643396e+12\n",
       "24       2023         ols  15.139311  2.447663e+11\n",
       "25       2023  exp_smooth  15.139361  1.063955e+11\n",
       "26       2023         xgb  15.157966  2.091417e+12\n",
       "27       2024         ols  28.058081  4.834143e+11\n",
       "28       2024  exp_smooth  28.058014  2.247528e+11\n",
       "29       2024         xgb  28.075434  2.115471e+12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_year</th>\n",
       "      <th>model</th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>ols</td>\n",
       "      <td>ope_be</td>\n",
       "      <td>0.015429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>ols</td>\n",
       "      <td>ret_9_1</td>\n",
       "      <td>0.011652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015</td>\n",
       "      <td>ols</td>\n",
       "      <td>ni_ivol</td>\n",
       "      <td>0.011297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015</td>\n",
       "      <td>ols</td>\n",
       "      <td>seas_1_1an</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015</td>\n",
       "      <td>ols</td>\n",
       "      <td>taccruals_at</td>\n",
       "      <td>0.009355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2024</td>\n",
       "      <td>xgb</td>\n",
       "      <td>betadown_252d</td>\n",
       "      <td>0.000877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2024</td>\n",
       "      <td>xgb</td>\n",
       "      <td>ni_me</td>\n",
       "      <td>0.000544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2024</td>\n",
       "      <td>xgb</td>\n",
       "      <td>eqpo_me</td>\n",
       "      <td>0.000319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2024</td>\n",
       "      <td>xgb</td>\n",
       "      <td>ope_be</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2024</td>\n",
       "      <td>xgb</td>\n",
       "      <td>seas_1_1an</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     eval_year model        feature  importance\n",
       "1         2015   ols         ope_be    0.015429\n",
       "5         2015   ols        ret_9_1    0.011652\n",
       "6         2015   ols        ni_ivol    0.011297\n",
       "9         2015   ols     seas_1_1an    0.009422\n",
       "10        2015   ols   taccruals_at    0.009355\n",
       "..         ...   ...            ...         ...\n",
       "495       2024   xgb  betadown_252d    0.000877\n",
       "496       2024   xgb          ni_me    0.000544\n",
       "497       2024   xgb        eqpo_me    0.000319\n",
       "498       2024   xgb         ope_be    0.000269\n",
       "499       2024   xgb     seas_1_1an    0.000257\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
