{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Model for Stock Return Prediction\n",
    "\n",
    "This notebook implements an ARIMA model for predicting stock returns using the hackathon dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bn/cx_ppcpx0ngbpf4h354g9_k80000gn/T/ipykernel_38877/1606108990.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path for data_loader import\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "from data_loader import load_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2025-09-21 22:09:58.836471\n"
     ]
    }
   ],
   "source": [
    "# For timing purpose\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "\n",
    "# Turn off pandas Setting with Copy Warning\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading data from: /Users/kevin/Coding Projects/Asset-Management-Hackathon-2025/data/ret_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# Load data using data_loader\n",
    "print(\"Loading data...\")\n",
    "raw = load_data(filename=\"ret_sample.csv\", parse_dates=[\"ret_eom\"], low_memory=False)\n",
    "print(f\"Data shape: {raw.shape}\")\n",
    "print(f\"Date range: {raw['ret_eom'].min()} to {raw['ret_eom'].max()}\")\n",
    "\n",
    "# Ensure the date column is properly converted to datetime\n",
    "raw['date'] = pd.to_datetime(raw['ret_eom'])\n",
    "print(f\"Date column type: {raw['date'].dtype}\")\n",
    "\n",
    "# Load list of predictors for stocks\n",
    "stock_vars = list(load_data(filename=\"factor_char_list.csv\")[\"variable\"].values)\n",
    "print(f\"Number of predictor variables: {len(stock_vars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the left hand side variable\n",
    "ret_var = \"stock_ret\"\n",
    "new_set = raw[raw[ret_var].notna()].copy()\n",
    "print(f\"Data after removing missing returns: {new_set.shape}\")\n",
    "\n",
    "# Transform each variable in each month to the same scale\n",
    "monthly = new_set.groupby(\"date\")\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for date, monthly_raw in monthly:\n",
    "    group = monthly_raw.copy()\n",
    "    # Rank transform each variable to [-1, 1]\n",
    "    for var in stock_vars:\n",
    "        var_median = group[var].median(skipna=True)\n",
    "        group[var] = group[var].fillna(var_median)  # Fill missing values with cross-sectional median\n",
    "        \n",
    "        group[var] = group[var].rank(method=\"dense\") - 1\n",
    "        group_max = group[var].max()\n",
    "        if group_max > 0:\n",
    "            group[var] = (group[var] / group_max) * 2 - 1\n",
    "        else:\n",
    "            group[var] = 0  # In case of all missing values\n",
    "            print(f\"Warning: {date}, {var} set to zero.\")\n",
    "    \n",
    "    # Add the adjusted values\n",
    "    data = pd.concat([data, group], ignore_index=True)\n",
    "\n",
    "print(f\"Processed data shape: {data.shape}\")\n",
    "print(f\"Date column in processed data type: {data['date'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check stationarity\n",
    "def check_stationarity(series, title=''):\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f'{title} ADF Statistic: {result[0]:.6f}')\n",
    "    print(f'p-value: {result[1]:.6f}')\n",
    "    print(f'Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'\\t{key}: {value:.3f}')\n",
    "    return result[1] < 0.05  # Return True if stationary\n",
    "\n",
    "# Function to find optimal ARIMA parameters\n",
    "def find_arima_params(series, max_p=3, max_d=2, max_q=3):\n",
    "    best_aic = np.inf\n",
    "    best_params = None\n",
    "    \n",
    "    for p in range(max_p + 1):\n",
    "        for d in range(max_d + 1):\n",
    "            for q in range(max_q + 1):\n",
    "                try:\n",
    "                    model = ARIMA(series, order=(p, d, q))\n",
    "                    fitted_model = model.fit()\n",
    "                    if fitted_model.aic < best_aic:\n",
    "                        best_aic = fitted_model.aic\n",
    "                        best_params = (p, d, q)\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    return best_params, best_aic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the starting date, counter, and output data\n",
    "starting = pd.to_datetime(\"20050101\", format=\"%Y%m%d\")\n",
    "counter = 0\n",
    "pred_out = pd.DataFrame()\n",
    "\n",
    "print(\"Starting ARIMA model training and prediction...\")\n",
    "\n",
    "# Estimation with expanding window\n",
    "while (starting + pd.DateOffset(years=11 + counter)) <= pd.to_datetime(\"20260101\", format=\"%Y%m%d\"):\n",
    "    cutoff = [\n",
    "        starting,\n",
    "        starting + pd.DateOffset(years=8 + counter),  # Use 8 years and expanding as training set\n",
    "        starting + pd.DateOffset(years=10 + counter),  # Use next 2 years as validation set\n",
    "        starting + pd.DateOffset(years=11 + counter),\n",
    "    ]  # Use next year as out-of-sample testing set\n",
    "    \n",
    "    print(f\"\\nProcessing period {counter + 1}: {cutoff[0].strftime('%Y-%m-%d')} to {cutoff[3].strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # Cut the sample into training, validation, and testing sets\n",
    "    train = data[(data[\"date\"] >= cutoff[0]) & (data[\"date\"] < cutoff[1])]\n",
    "    validate = data[(data[\"date\"] >= cutoff[1]) & (data[\"date\"] < cutoff[2])]\n",
    "    test = data[(data[\"date\"] >= cutoff[2]) & (data[\"date\"] < cutoff[3])]\n",
    "    \n",
    "    print(f\"Training set: {len(train)} observations\")\n",
    "    print(f\"Validation set: {len(validate)} observations\")\n",
    "    print(f\"Test set: {len(test)} observations\")\n",
    "    \n",
    "    # Prepare output data\n",
    "    reg_pred = test[[\"year\", \"month\", \"ret_eom\", \"id\", ret_var]].copy()\n",
    "    \n",
    "    # For ARIMA, we'll work with the time series of returns\n",
    "    # We'll create a time series for each stock and predict individually\n",
    "    arima_predictions = []\n",
    "    \n",
    "    # Get unique stocks in test set\n",
    "    test_stocks = test['id'].unique()\n",
    "    print(f\"Predicting for {len(test_stocks)} stocks...\")\n",
    "    \n",
    "    for stock_id in test_stocks:\n",
    "        # Get historical data for this stock\n",
    "        stock_train = train[train['id'] == stock_id].sort_values('date')\n",
    "        stock_val = validate[validate['id'] == stock_id].sort_values('date')\n",
    "        stock_test = test[test['id'] == stock_id].sort_values('date')\n",
    "        \n",
    "        if len(stock_train) < 10:  # Need minimum observations for ARIMA\n",
    "            # Use simple mean prediction if not enough data\n",
    "            mean_ret = stock_train[ret_var].mean() if len(stock_train) > 0 else 0\n",
    "            arima_pred = [mean_ret] * len(stock_test)\n",
    "        else:\n",
    "            # Prepare time series\n",
    "            train_series = stock_train[ret_var].values\n",
    "            \n",
    "            # Check stationarity\n",
    "            is_stationary = check_stationarity(pd.Series(train_series), f'Stock {stock_id}')\n",
    "            \n",
    "            # Find optimal ARIMA parameters\n",
    "            best_params, best_aic = find_arima_params(pd.Series(train_series))\n",
    "            \n",
    "            if best_params is not None:\n",
    "                try:\n",
    "                    # Fit ARIMA model\n",
    "                    model = ARIMA(train_series, order=best_params)\n",
    "                    fitted_model = model.fit()\n",
    "                    \n",
    "                    # Make predictions\n",
    "                    arima_pred = fitted_model.forecast(steps=len(stock_test))\n",
    "                    \n",
    "                    # If forecast returns a single value, repeat it\n",
    "                    if len(arima_pred) == 1:\n",
    "                        arima_pred = [arima_pred[0]] * len(stock_test)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error fitting ARIMA for stock {stock_id}: {e}\")\n",
    "                    # Fallback to mean prediction\n",
    "                    mean_ret = stock_train[ret_var].mean()\n",
    "                    arima_pred = [mean_ret] * len(stock_test)\n",
    "            else:\n",
    "                # Fallback to mean prediction\n",
    "                mean_ret = stock_train[ret_var].mean()\n",
    "                arima_pred = [mean_ret] * len(stock_test)\n",
    "        \n",
    "        # Store predictions\n",
    "        for i, (_, row) in enumerate(stock_test.iterrows()):\n",
    "            if i < len(arima_pred):\n",
    "                arima_predictions.append(arima_pred[i])\n",
    "            else:\n",
    "                arima_predictions.append(arima_pred[-1] if arima_pred else 0)\n",
    "    \n",
    "    # Add ARIMA predictions to output\n",
    "    reg_pred[\"arima\"] = arima_predictions\n",
    "    \n",
    "    # Add to the output data\n",
    "    pred_out = pd.concat([pred_out, reg_pred], ignore_index=True)\n",
    "    \n",
    "    # Go to the next year\n",
    "    counter += 1\n",
    "    \n",
    "    # Break if we've processed enough periods (optional limit)\n",
    "    if counter >= 5:  # Limit for demonstration\n",
    "        break\n",
    "\n",
    "print(f\"\\nCompleted processing {counter} periods\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the predicted values to CSV\n",
    "output_path = Path.cwd().parent / \"data\" / \"arima_predictions.csv\"\n",
    "print(f\"Saving predictions to: {output_path}\")\n",
    "pred_out.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nPrediction results shape: {pred_out.shape}\")\n",
    "print(f\"Columns: {list(pred_out.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the OOS R²\n",
    "yreal = pred_out[ret_var].values\n",
    "ypred_arima = pred_out[\"arima\"].values\n",
    "\n",
    "# Calculate R²\n",
    "r2_arima = 1 - np.sum(np.square((yreal - ypred_arima))) / np.sum(np.square(yreal))\n",
    "print(f\"ARIMA OOS R²: {r2_arima:.6f}\")\n",
    "\n",
    "# Calculate additional metrics\n",
    "mse_arima = mean_squared_error(yreal, ypred_arima)\n",
    "rmse_arima = np.sqrt(mse_arima)\n",
    "mae_arima = np.mean(np.abs(yreal - ypred_arima))\n",
    "\n",
    "print(f\"ARIMA MSE: {mse_arima:.6f}\")\n",
    "print(f\"ARIMA RMSE: {rmse_arima:.6f}\")\n",
    "print(f\"ARIMA MAE: {mae_arima:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check what data we have\n",
    "print(\"=== DEBUGGING INFORMATION ===\")\n",
    "print(f\"Total data shape: {data.shape}\")\n",
    "print(f\"Date range in data: {data['date'].min()} to {data['date'].max()}\")\n",
    "print(f\"Unique dates: {data['date'].nunique()}\")\n",
    "print(f\"Unique stocks: {data['id'].nunique()}\")\n",
    "\n",
    "# Check if pred_out has any data\n",
    "print(f\"\\nPrediction output shape: {pred_out.shape}\")\n",
    "print(f\"Prediction output columns: {list(pred_out.columns) if not pred_out.empty else 'EMPTY'}\")\n",
    "\n",
    "if pred_out.empty:\n",
    "    print(\"ERROR: No predictions were generated!\")\n",
    "    print(\"This could be due to:\")\n",
    "    print(\"1. Date filtering is too restrictive\")\n",
    "    print(\"2. No data in the specified date ranges\")\n",
    "    print(\"3. ARIMA model failed for all stocks\")\n",
    "else:\n",
    "    print(f\"Number of predictions: {len(pred_out)}\")\n",
    "    print(f\"Sample predictions:\\n{pred_out.head()}\")\n",
    "    \n",
    "    # Check for missing values in predictions\n",
    "    print(f\"Missing values in ARIMA predictions: {pred_out['arima'].isna().sum()}\")\n",
    "    print(f\"Missing values in actual returns: {pred_out[ret_var].isna().sum()}\")\n",
    "    \n",
    "    # Only calculate metrics if we have data\n",
    "    if len(pred_out) > 0:\n",
    "        yreal = pred_out[ret_var].values\n",
    "        ypred_arima = pred_out[\"arima\"].values\n",
    "        \n",
    "        # Remove any NaN values\n",
    "        mask = ~(np.isnan(yreal) | np.isnan(ypred_arima))\n",
    "        yreal_clean = yreal[mask]\n",
    "        ypred_clean = ypred_arima[mask]\n",
    "        \n",
    "        print(f\"Clean data points: {len(yreal_clean)}\")\n",
    "        \n",
    "        if len(yreal_clean) > 0:\n",
    "            # Calculate R²\n",
    "            r2_arima = 1 - np.sum(np.square((yreal_clean - ypred_clean))) / np.sum(np.square(yreal_clean))\n",
    "            print(f\"ARIMA OOS R²: {r2_arima:.6f}\")\n",
    "            \n",
    "            # Calculate additional metrics\n",
    "            mse_arima = mean_squared_error(yreal_clean, ypred_clean)\n",
    "            rmse_arima = np.sqrt(mse_arima)\n",
    "            mae_arima = np.mean(np.abs(yreal_clean - ypred_clean))\n",
    "            \n",
    "            print(f\"ARIMA MSE: {mse_arima:.6f}\")\n",
    "            print(f\"ARIMA RMSE: {rmse_arima:.6f}\")\n",
    "            print(f\"ARIMA MAE: {mae_arima:.6f}\")\n",
    "        else:\n",
    "            print(\"ERROR: No valid data points after removing NaN values!\")\n",
    "    else:\n",
    "        print(\"ERROR: No predictions to evaluate!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actual values\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Scatter plot\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(yreal, ypred_arima, alpha=0.5)\n",
    "plt.plot([yreal.min(), yreal.max()], [yreal.min(), yreal.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Returns')\n",
    "plt.ylabel('Predicted Returns')\n",
    "plt.title('ARIMA: Predicted vs Actual Returns')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals plot\n",
    "plt.subplot(2, 2, 2)\n",
    "residuals = yreal - ypred_arima\n",
    "plt.scatter(ypred_arima, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Returns')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('ARIMA: Residuals vs Predicted')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Time series plot (first 1000 observations)\n",
    "plt.subplot(2, 2, 3)\n",
    "n_plot = min(1000, len(yreal))\n",
    "plt.plot(yreal[:n_plot], label='Actual', alpha=0.7)\n",
    "plt.plot(ypred_arima[:n_plot], label='Predicted', alpha=0.7)\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('ARIMA: Time Series (First 1000 obs)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram of residuals\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(residuals, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('ARIMA: Distribution of Residuals')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics\n",
    "print(\"\\n=== ARIMA Model Summary ===\")\n",
    "print(f\"Total predictions: {len(pred_out)}\")\n",
    "print(f\"R²: {r2_arima:.6f}\")\n",
    "print(f\"RMSE: {rmse_arima:.6f}\")\n",
    "print(f\"MAE: {mae_arima:.6f}\")\n",
    "print(f\"\\nActual returns - Mean: {np.mean(yreal):.6f}, Std: {np.std(yreal):.6f}\")\n",
    "print(f\"Predicted returns - Mean: {np.mean(ypred_arima):.6f}, Std: {np.std(ypred_arima):.6f}\")\n",
    "\n",
    "# For timing purpose\n",
    "print(f\"\\nEnd time: {datetime.datetime.now()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
